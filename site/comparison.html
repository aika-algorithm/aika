<!DOCTYPE HTML>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Why AIKA? - A Different Approach to Neural Networks</title>
    <link rel="stylesheet" href="css/style.css" neuronType="text/css">
    <link rel="shortcut icon" href="images/favicon.png" />
</head>
<body>
<div id="header">
    <div>
        <div class="logo">
            <a rel="canonical" href="https://aika.network"></a>
        </div>
        <ul id="navigation">
            <li>
                <a href="index.html">About</a>
            </li>
            <li>
                <a href="installation.html">Installation</a>
            </li>
            <li>
                <a href="usage.html">Tutorial</a>
            </li>
            <li class="active">
                <a href="comparison.html">Why AIKA?</a>
            </li>
            <li>
                <a href="resources.html">Resources</a>
            </li>
            <li>
                <a href="blog.html">Blog</a>
            </li>
            <li>
                <a href="https://github.com/aika-algorithm/aika">GitHub</a>
            </li>
        </ul>
    </div>
</div>
<div id="contents">
    <div id="features">
        <h1>Why AIKA? A Different Approach to Neural Networks</h1>
        <p>
            AIKA takes a fundamentally different approach compared to traditional deep learning frameworks like PyTorch. Like PyTorch, AIKA combines Python for model definition with high-performance C++ for execution, but the underlying philosophy and execution model are quite different.
        </p>
        <p style="background-color: #E8F5E9; padding: 12px; border-left: 4px solid #4CAF50; margin: 15px 0;">
            <strong>üéØ TL;DR:</strong> AIKA is an <strong>event-driven, dynamically-structured neural network framework</strong> designed for interpretability, sparse computation, and research into alternative AI architectures.
        </p>

        <h2>Architecture Comparison</h2>
        <p>
            Both AIKA and PyTorch use a <strong>Python frontend with C++ backend</strong> architecture, but their approaches diverge significantly:
        </p>
        <table border="1" cellspacing="0" cellpadding="5">
            <tr>
                <th>Aspect</th>
                <th>AIKA (C++ + Python)</th>
                <th>PyTorch (C++ + Python)</th>
            </tr>
            <tr>
                <td><b>Backend</b></td>
                <td>Custom C++20 core with pybind11 bindings</td>
                <td>libtorch (C++) with Python bindings</td>
            </tr>
            <tr>
                <td><b>Data Model</b></td>
                <td>Dynamically instantiated object graph</td>
                <td>Predefined tensor dimensions</td>
            </tr>
            <tr>
                <td><b>Computation Model</b></td>
                <td>Event-driven processing via activation queue</td>
                <td>Batch-based matrix operations</td>
            </tr>
            <tr>
                <td><b>Processing</b></td>
                <td>Asynchronous, sparse activations</td>
                <td>Synchronous, dense computations</td>
            </tr>
            <tr>
                <td><b>Architecture</b></td>
                <td>Type-hierarchy defining neural elements</td>
                <td>Layered networks using tensor algebra</td>
            </tr>
            <tr>
                <td><b>Flexibility</b></td>
                <td>Neurons and connections instantiated at runtime</td>
                <td>Fixed-size tensors and layers</td>
            </tr>
            <tr>
                <td><b>Use Case</b></td>
                <td>Research, interpretable AI, dynamic structures</td>
                <td>Production, high-throughput numerical computation</td>
            </tr>
        </table>

        <h2>Key Differences</h2>

        <h3>1. Dynamic Object Graph vs. Static Tensor Ops</h3>
        <p>
            <strong>PyTorch:</strong> Uses predefined tensor operations (linear layers, conv layers, etc.) on fixed-size vectors/matrices. Network structure is defined upfront with set dimensions.
        </p>
        <p>
            <strong>AIKA:</strong> Builds computations through dynamically instantiated objects derived from a type hierarchy. Networks can spawn new neuron or activation instances on the fly, allowing variable structures and sparsely populated data to be handled naturally.
        </p>

        <h3>2. Event-Driven Asynchrony vs. Synchronous Execution</h3>
        <p>
            <strong>PyTorch:</strong> Computations proceed synchronously (forward pass, then backward pass, typically on batched data).
        </p>
        <p>
            <strong>AIKA:</strong> Employs an event-driven mechanism with lexicographic queue ordering: <code>(round, phase, -priority, timestamp)</code>. When certain conditions are met (e.g., a neuron's threshold is exceeded), an event is queued and processed in order. Different parts of the network can update at different times, efficiently handling sparse or sequentially dependent activations.
        </p>

        <h3>3. Flexible Topology vs. Layered Architecture</h3>
        <p>
            <strong>PyTorch:</strong> Models are usually defined as a stack of layers or modules that data flows through. The computation graph is generally fixed once the model is defined (aside from control-flow logic in dynamic graphs).
        </p>
        <p>
            <strong>AIKA:</strong> Does away with a strictly layered design. The functional graph is tied to objects created during runtime. Because of the type hierarchy and dynamic instantiation, the network topology can be more flexible and adaptive‚Äîthe structure can change depending on the input and the events triggered.
        </p>

        <h2>Advantages of AIKA</h2>
        <ul>
            <li><b>Sparse & Efficient:</b> AIKA only activates relevant parts of the network, reducing computation time for sparse data.</li>
            <li><b>More Interpretable:</b> Individual activations are objects that can be traced back to symbolic representations, making the network more transparent.</li>
            <li><b>Flexible Topology:</b> The network structure evolves dynamically rather than being fixed, enabling adaptive architectures.</li>
            <li><b>Type-Based Design:</b> The type hierarchy provides better organization and reuse when building complex models.</li>
            <li><b>C++ Performance:</b> High-performance C++20 core with modern design patterns (builder pattern, smart pointers, etc.).</li>
        </ul>

        <h2>Current Implementation Status</h2>
        <p>
            <strong>Maturity Level:</strong> Beta (Active Development, ~72% complete)
        </p>
        <ul>
            <li>‚úÖ <strong>Fields Module:</strong> 100% complete and production-ready</li>
            <li>‚ö†Ô∏è <strong>Network Module:</strong> 85% complete (core functionality working)</li>
            <li>‚ö†Ô∏è <strong>Transformer:</strong> 60% complete (type structure done, attention mechanism in progress)</li>
        </ul>
        <p>
            PyTorch is a mature, production-ready framework optimized for high-throughput numerical computation with static graphs and batched data. AIKA, by contrast, explores a more <strong>adaptive, event-driven paradigm</strong> where the focus is on individual activations and their interactions. AIKA's approach may be advantageous for research into neural architectures that require dynamic structure or need to capture fine-grained causality and interactions not easily represented in matrix form.
        </p>

        <h2>When to Use AIKA: Real-World Scenarios</h2>

        <h3>‚úÖ Ideal Use Cases</h3>

        <p><strong>1. Research into Alternative AI Architectures</strong></p>
        <p style="margin-left: 20px;">
            <em>Scenario:</em> You're researching neural architectures that don't fit the standard layer-by-layer paradigm.<br/>
            <em>Why AIKA:</em> Dynamic object instantiation and type-based design let you experiment with novel network topologies that PyTorch's tensor operations can't easily express.
        </p>

        <p><strong>2. Interpretable AI Systems</strong></p>
        <p style="margin-left: 20px;">
            <em>Scenario:</em> You need to explain why your network made a specific decision (e.g., medical diagnosis, legal reasoning).<br/>
            <em>Why AIKA:</em> Individual activations are traceable objects linked to symbolic representations, making it easier to understand the reasoning chain.
        </p>

        <p><strong>3. Sparse, Event-Driven Processing</strong></p>
        <p style="margin-left: 20px;">
            <em>Scenario:</em> Your data is sparse (e.g., knowledge graphs, symbolic reasoning) and only parts of the network should activate.<br/>
            <em>Why AIKA:</em> Event-driven queue processes only active neurons, avoiding wasteful computation on irrelevant paths.
        </p>

        <p><strong>4. Dynamic Network Structures</strong></p>
        <p style="margin-left: 20px;">
            <em>Scenario:</em> Your network topology needs to change based on input (e.g., program synthesis, adaptive reasoning).<br/>
            <em>Why AIKA:</em> Runtime instantiation allows the network structure to adapt dynamically to each input.
        </p>

        <h3>‚ùå Not Ideal For</h3>
        <ul>
            <li><strong>Production deep learning systems:</strong> PyTorch/TensorFlow are more mature and battle-tested</li>
            <li><strong>High-throughput batch processing:</strong> AIKA's event-driven model trades throughput for flexibility</li>
            <li><strong>Standard computer vision/NLP:</strong> Existing frameworks have optimized implementations</li>
            <li><strong>Projects requiring immediate stability:</strong> AIKA is in beta (72% complete)</li>
        </ul>

        <h2>Ready to Try AIKA?</h2>
        <p style="margin-top: 20px;">
            <a href="installation.html" style="display: inline-block; padding: 12px 24px; background-color: #4CAF50; color: white; text-decoration: none; border-radius: 4px; font-weight: bold;">Get Started ‚Üí</a>
            &nbsp;&nbsp;
            <a href="resources.html" style="display: inline-block; padding: 12px 24px; background-color: #9C27B0; color: white; text-decoration: none; border-radius: 4px; font-weight: bold;">Documentation</a>
        </p>
        <p style="margin-top: 15px;">
            Begin with the <a href="installation.html">Installation Guide</a>, follow the <a href="usage.html">Tutorial</a>, or explore the <a href="resources.html">full documentation</a> and <a href="https://github.com/aika-algorithm/aika/tree/main/specs">formal specifications</a>.
        </p>
    </div>
</div>
</body>
</html>